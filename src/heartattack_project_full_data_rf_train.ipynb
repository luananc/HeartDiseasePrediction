{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[42m[ OK ]\u001b[0m Python version is 3.11.4\n",
      "\n",
      "\u001b[42m[ OK ]\u001b[0m numpy version 1.24.4 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m matplotlib version 3.7.2 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m sklearn version 1.3.0 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m pandas version 2.0.3 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m xgboost version 1.7.6 is installed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[42m[ OK ]\u001b[0m shap version 0.42.1 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m seaborn version 0.12.2 is installed.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from packaging.version import parse as Version\n",
    "from platform import python_version\n",
    "\n",
    "OK = '\\x1b[42m[ OK ]\\x1b[0m'\n",
    "FAIL = \"\\x1b[41m[FAIL]\\x1b[0m\"\n",
    "\n",
    "try:\n",
    "    import importlib\n",
    "except ImportError:\n",
    "    print(FAIL, \"Python version 3.11 is required,\"\n",
    "                \" but %s is installed.\" % sys.version)\n",
    "\n",
    "def import_version(pkg, min_ver, fail_msg=\"\"):\n",
    "    mod = None\n",
    "    try:\n",
    "        mod = importlib.import_module(pkg)\n",
    "        if pkg in {'PIL'}:\n",
    "            ver = mod.VERSION\n",
    "        else:\n",
    "            ver = mod.__version__\n",
    "        if Version(ver) == Version(min_ver):\n",
    "            print(OK, \"%s version %s is installed.\"\n",
    "                  % (lib, min_ver))\n",
    "        else:\n",
    "            print(FAIL, \"%s version %s is required, but %s installed.\"\n",
    "                  % (lib, min_ver, ver))    \n",
    "    except ImportError:\n",
    "        print(FAIL, '%s not installed. %s' % (pkg, fail_msg))\n",
    "    return mod\n",
    "\n",
    "\n",
    "# first check the python version\n",
    "pyversion = Version(python_version())\n",
    "\n",
    "if pyversion >= Version(\"3.11.4\"):\n",
    "    print(OK, \"Python version is %s\" % pyversion)\n",
    "elif pyversion < Version(\"3.11\"):\n",
    "    print(FAIL, \"Python version 3.11 is required,\"\n",
    "                \" but %s is installed.\" % pyversion)\n",
    "else:\n",
    "    print(FAIL, \"Unknown Python version: %s\" % pyversion)\n",
    "\n",
    "    \n",
    "print()\n",
    "requirements = {'numpy': \"1.24.4\", 'matplotlib': \"3.7.2\",'sklearn': \"1.3.0\", \n",
    "                'pandas': \"2.0.3\",'xgboost': \"1.7.6\", 'shap': \"0.42.1\", 'seaborn': \"0.12.2\"}\n",
    "\n",
    "# now the dependencies\n",
    "for lib, required_version in list(requirements.items()):\n",
    "    import_version(lib, required_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, fbeta_score, auc,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "\n",
    "import warnings\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Set\n",
      "X: (308854, 18)\n",
      "y: (308854,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "df = pd.read_csv('../data/CVD_cleaned.csv')\n",
    "df.head()\n",
    "ftrs = df.columns\n",
    "\n",
    "random_state = 56\n",
    "\n",
    "X = df.drop(labels=['Heart_Disease'], axis=1)\n",
    "y = df['Heart_Disease']\n",
    "\n",
    "label_mapping = {'No': 0, 'Yes': 1}\n",
    "y = y.map(label_mapping)\n",
    "\n",
    "X_subset, _, y_subset, _ = train_test_split(X, y, test_size=0.99, stratify=y, random_state=56)\n",
    "\n",
    "print(\"Full Set\")\n",
    "print('X:',X.shape)\n",
    "print('y:',y.shape)\n",
    "#print(\"Subset Set\")\n",
    "#print('X_subset:',X_subset.shape)\n",
    "#print('y_subset:',y_subset.shape)\n",
    "\n",
    "cat_ftrs = ['Checkup','Exercise','Skin_Cancer','Other_Cancer', 'Depression', 'Diabetes', 'Arthritis', 'Sex','Smoking_History']\n",
    "ordinal_ftrs = ['General_Health','Age_Category',]\n",
    "ordinal_cats = [['Poor','Fair','Good','Very Good','Excellent'],\\\n",
    "               ['18-24','25-29','30-34','35-39','40-44','45-49','50-54','55-59','60-64','65-69','70-74','75-79','80+']]\n",
    "num_ftrs = ['Height_(cm)', 'Weight_(kg)', 'BMI', 'Alcohol_Consumption', 'Fruit_Consumption',\n",
    "       'Green_Vegetables_Consumption', 'FriedPotato_Consumption']\n",
    "\n",
    "# one-hot encoder\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(sparse_output=False,handle_unknown='ignore'))])\n",
    "\n",
    "# ordinal encoder\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('ordinal', OrdinalEncoder(categories = ordinal_cats))])\n",
    "\n",
    "# standard scaler\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# collect the transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs),\n",
    "        ('ord', ordinal_transformer, ordinal_ftrs)])\n",
    "final_scaler = StandardScaler()\n",
    "prep = Pipeline(steps=[('preprocessor', preprocessor)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, Y = df['Heart_Disease'].value_counts()\n",
    "baseline_recall = Y/(N+Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state 1\n",
      "(61771, 18)\n",
      "Fitting 1 folds for each of 100 candidates, totalling 100 fits\n",
      "Random state 2\n",
      "(61771, 18)\n",
      "Fitting 1 folds for each of 100 candidates, totalling 100 fits\n",
      "Random state 3\n",
      "(61771, 18)\n",
      "Fitting 1 folds for each of 100 candidates, totalling 100 fits\n",
      "Random state 4\n",
      "(61771, 18)\n",
      "Fitting 1 folds for each of 100 candidates, totalling 100 fits\n",
      "Random state 5\n",
      "(61771, 18)\n",
      "Fitting 1 folds for each of 100 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "nr_states = 5\n",
    "rf_scores = []\n",
    "rf_models = []\n",
    "rf_test_sets = []\n",
    "\n",
    "for i in range(nr_states):\n",
    "    print('Random state', i + 1)\n",
    "\n",
    "    X_train, X_other, y_train, y_other = train_test_split(X, y, train_size=0.6, stratify=y, random_state=56*i)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_other, y_other, train_size=0.5, stratify=y_other, random_state=56*i)\n",
    "    column_names = X.columns\n",
    "\n",
    "    X_combined = np.concatenate([X_train, X_val])\n",
    "    X_combined = pd.DataFrame(X_combined, columns=column_names)\n",
    "    y_combined = np.concatenate([y_train, y_val])\n",
    "    split_index = [-1]*len(X_train) + [0]*len(X_val)\n",
    "    fixedval = PredefinedSplit(test_fold=split_index)\n",
    "\n",
    "    print(X_test.shape)\n",
    "\n",
    "    pipe = make_pipeline(prep, RandomForestClassifier(n_jobs=-1, random_state=56*i))\n",
    "\n",
    "    param_grid = {\n",
    "        'randomforestclassifier__max_depth': [1, 3, 10, 30, 100],\n",
    "        'randomforestclassifier__max_features': [0.25, 0.5, 0.75, 1.0],\n",
    "        'randomforestclassifier__class_weight': [None, 'balanced', 'balanced_subsample', {0: 1, 1: 10}, {0: 1, 1: 15}]\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(pipe, param_grid, cv=fixedval, scoring='recall', verbose=1, n_jobs=-1)\n",
    "    grid.fit(X_combined, y_combined)\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "    rf_models.append(best_model)\n",
    "\n",
    "    for X_save, y_save, dataset_name_save in [(X_train, y_train, 'train'), (X_val, y_val, 'validation'), (X_test, y_test, 'test')]:\n",
    "        y_pred = best_model.predict(X_save)\n",
    "        precision, recall, _ = precision_recall_curve(y_save, best_model.predict_proba(X_save)[:, 1])\n",
    "        auc_pr = auc(recall, precision)\n",
    "        score = {\n",
    "            'dataset': dataset_name_save,\n",
    "            'state': i + 1,\n",
    "            'precision': precision_score(y_save, y_pred, zero_division=0),\n",
    "            'recall': recall_score(y_save, y_pred),\n",
    "            'f2': fbeta_score(y_save, y_pred, beta=2),\n",
    "            'auc-pr': auc_pr\n",
    "        }\n",
    "        rf_scores.append(score)\n",
    "\n",
    "    rf_test_sets.append({'X_test': X_test, 'y_test': y_test, 'state': i + 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>state</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f2</th>\n",
       "      <th>auc-pr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0.144045</td>\n",
       "      <td>0.892345</td>\n",
       "      <td>0.437643</td>\n",
       "      <td>0.239416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validation</td>\n",
       "      <td>1</td>\n",
       "      <td>0.144944</td>\n",
       "      <td>0.894073</td>\n",
       "      <td>0.439633</td>\n",
       "      <td>0.242094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>0.143526</td>\n",
       "      <td>0.889467</td>\n",
       "      <td>0.436132</td>\n",
       "      <td>0.241183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>0.129805</td>\n",
       "      <td>0.934326</td>\n",
       "      <td>0.417188</td>\n",
       "      <td>0.239643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>validation</td>\n",
       "      <td>2</td>\n",
       "      <td>0.128905</td>\n",
       "      <td>0.935322</td>\n",
       "      <td>0.415481</td>\n",
       "      <td>0.247448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>0.129860</td>\n",
       "      <td>0.938326</td>\n",
       "      <td>0.417938</td>\n",
       "      <td>0.244925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>0.137657</td>\n",
       "      <td>0.917974</td>\n",
       "      <td>0.430224</td>\n",
       "      <td>0.237719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>validation</td>\n",
       "      <td>3</td>\n",
       "      <td>0.136302</td>\n",
       "      <td>0.912495</td>\n",
       "      <td>0.426613</td>\n",
       "      <td>0.236591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>0.136520</td>\n",
       "      <td>0.914497</td>\n",
       "      <td>0.427390</td>\n",
       "      <td>0.232981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>0.126581</td>\n",
       "      <td>0.935327</td>\n",
       "      <td>0.410621</td>\n",
       "      <td>0.228351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>validation</td>\n",
       "      <td>4</td>\n",
       "      <td>0.126497</td>\n",
       "      <td>0.936924</td>\n",
       "      <td>0.410691</td>\n",
       "      <td>0.226331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test</td>\n",
       "      <td>4</td>\n",
       "      <td>0.127703</td>\n",
       "      <td>0.942331</td>\n",
       "      <td>0.414064</td>\n",
       "      <td>0.237617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "      <td>0.126840</td>\n",
       "      <td>0.942134</td>\n",
       "      <td>0.412213</td>\n",
       "      <td>0.234127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>validation</td>\n",
       "      <td>5</td>\n",
       "      <td>0.126608</td>\n",
       "      <td>0.938326</td>\n",
       "      <td>0.411139</td>\n",
       "      <td>0.225087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>0.127068</td>\n",
       "      <td>0.936524</td>\n",
       "      <td>0.411831</td>\n",
       "      <td>0.239811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset  state  precision    recall        f2    auc-pr\n",
       "0        train      1   0.144045  0.892345  0.437643  0.239416\n",
       "1   validation      1   0.144944  0.894073  0.439633  0.242094\n",
       "2         test      1   0.143526  0.889467  0.436132  0.241183\n",
       "3        train      2   0.129805  0.934326  0.417188  0.239643\n",
       "4   validation      2   0.128905  0.935322  0.415481  0.247448\n",
       "5         test      2   0.129860  0.938326  0.417938  0.244925\n",
       "6        train      3   0.137657  0.917974  0.430224  0.237719\n",
       "7   validation      3   0.136302  0.912495  0.426613  0.236591\n",
       "8         test      3   0.136520  0.914497  0.427390  0.232981\n",
       "9        train      4   0.126581  0.935327  0.410621  0.228351\n",
       "10  validation      4   0.126497  0.936924  0.410691  0.226331\n",
       "11        test      4   0.127703  0.942331  0.414064  0.237617\n",
       "12       train      5   0.126840  0.942134  0.412213  0.234127\n",
       "13  validation      5   0.126608  0.938326  0.411139  0.225087\n",
       "14        test      5   0.127068  0.936524  0.411831  0.239811"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rf_scores)\n",
    "#rf_test_sets[1]['X_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train recall mean: 0.9244210104785424\n",
      "validation recall mean: 0.9234281137364839\n",
      "test recall mean: 0.9242290748898678\n",
      "test recall standard deviation: 0.01990295797470321\n",
      "42.3745 standard deviations above the baseline\n"
     ]
    }
   ],
   "source": [
    "rf_score = pd.DataFrame(rf_scores)\n",
    "rf_score\n",
    "rf_train_recall = rf_score[rf_score['dataset'] == 'train']['recall']\n",
    "rf_val_recall = rf_score[rf_score['dataset'] == 'validation']['recall']\n",
    "rf_test_recall = rf_score[rf_score['dataset'] == 'test']['recall']\n",
    "\n",
    "print('train recall mean:',np.mean(rf_train_recall))\n",
    "print('validation recall mean:',np.mean(rf_val_recall))\n",
    "print('test recall mean:',np.mean(rf_test_recall))\n",
    "print('test recall standard deviation:',np.std(rf_test_recall))\n",
    "print(round((np.mean(rf_test_recall)-baseline_recall)/np.std(rf_test_recall),4),'standard deviations above the baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('rf_results_final.pkl', 'wb') as file:\n",
    "    pickle.dump({'scores': rf_scores, 'models': rf_models, 'test_sets': rf_test_sets}, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rf_results_final.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    rf_scores = data['scores']\n",
    "    rf_models = data['models']\n",
    "    rf_test_sets = data['test_sets']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bc7e3361d9d4e6acf19e6d3debb289c8e445d5570286ce39fb3214745b4bcdf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
