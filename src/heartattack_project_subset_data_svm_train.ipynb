{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"BtxktPHilxmh","outputId":"1faabfa4-2389-43e0-e298-141b88133735"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[42m[ OK ]\u001b[0m Python version is 3.11.4\n","\n","\u001b[42m[ OK ]\u001b[0m numpy version 1.24.4 is installed.\n","\u001b[42m[ OK ]\u001b[0m matplotlib version 3.7.2 is installed.\n","\u001b[42m[ OK ]\u001b[0m sklearn version 1.3.0 is installed.\n","\u001b[42m[ OK ]\u001b[0m pandas version 2.0.3 is installed.\n","\u001b[42m[ OK ]\u001b[0m xgboost version 1.7.6 is installed.\n"]},{"name":"stderr","output_type":"stream","text":["Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[42m[ OK ]\u001b[0m shap version 0.42.1 is installed.\n","\u001b[42m[ OK ]\u001b[0m seaborn version 0.12.2 is installed.\n"]}],"source":["from __future__ import print_function\n","from packaging.version import parse as Version\n","from platform import python_version\n","\n","OK = '\\x1b[42m[ OK ]\\x1b[0m'\n","FAIL = \"\\x1b[41m[FAIL]\\x1b[0m\"\n","\n","try:\n","    import importlib\n","except ImportError:\n","    print(FAIL, \"Python version 3.11 is required,\"\n","                \" but %s is installed.\" % sys.version)\n","\n","def import_version(pkg, min_ver, fail_msg=\"\"):\n","    mod = None\n","    try:\n","        mod = importlib.import_module(pkg)\n","        if pkg in {'PIL'}:\n","            ver = mod.VERSION\n","        else:\n","            ver = mod.__version__\n","        if Version(ver) == Version(min_ver):\n","            print(OK, \"%s version %s is installed.\"\n","                  % (lib, min_ver))\n","        else:\n","            print(FAIL, \"%s version %s is required, but %s installed.\"\n","                  % (lib, min_ver, ver))\n","    except ImportError:\n","        print(FAIL, '%s not installed. %s' % (pkg, fail_msg))\n","    return mod\n","\n","\n","# first check the python version\n","pyversion = Version(python_version())\n","\n","if pyversion >= Version(\"3.11.4\"):\n","    print(OK, \"Python version is %s\" % pyversion)\n","elif pyversion < Version(\"3.11\"):\n","    print(FAIL, \"Python version 3.11 is required,\"\n","                \" but %s is installed.\" % pyversion)\n","else:\n","    print(FAIL, \"Unknown Python version: %s\" % pyversion)\n","\n","\n","print()\n","requirements = {'numpy': \"1.24.4\", 'matplotlib': \"3.7.2\",'sklearn': \"1.3.0\",\n","                'pandas': \"2.0.3\",'xgboost': \"1.7.6\", 'shap': \"0.42.1\", 'seaborn': \"0.12.2\"}\n","\n","# now the dependencies\n","for lib, required_version in list(requirements.items()):\n","    import_version(lib, required_version)"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":285,"status":"ok","timestamp":1701505029117,"user":{"displayName":"Yicheng Lu","userId":"02397941240840373956"},"user_tz":300},"id":"iwHTqtHHlxml"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline, make_pipeline\n","from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n","from sklearn.model_selection import PredefinedSplit\n","\n","from sklearn.svm import SVC\n","\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import (\n","    precision_score, recall_score, fbeta_score, auc,\n","    precision_recall_curve, average_precision_score\n",")\n","\n","import warnings\n","import pickle"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1338,"status":"ok","timestamp":1701505071899,"user":{"displayName":"Yicheng Lu","userId":"02397941240840373956"},"user_tz":300},"id":"INZr2os6lxmm","outputId":"fe9437f6-31d6-4013-b288-aaea7fab3d08"},"outputs":[{"name":"stdout","output_type":"stream","text":["Full Set\n","X: (308854, 18)\n","y: (308854,)\n","Subset Set\n","X_subset: (123541, 18)\n","y_subset: (123541,)\n"]}],"source":["df = pd.read_csv('../data/CVD_cleaned.csv')\n","df.head()\n","\n","random_state = 56\n","\n","X = df.drop(labels=['Heart_Disease'], axis=1)\n","y = df['Heart_Disease']\n","\n","label_mapping = {'No': 0, 'Yes': 1}\n","y = y.map(label_mapping)\n","\n","X_subset, _, y_subset, _ = train_test_split(X, y, test_size=0.6, stratify=y, random_state=56)\n","\n","print(\"Full Set\")\n","print('X:',X.shape)\n","print('y:',y.shape)\n","print(\"Subset Set\")\n","print('X_subset:',X_subset.shape)\n","print('y_subset:',y_subset.shape)\n","\n","cat_ftrs = ['Checkup','Exercise','Skin_Cancer','Other_Cancer', 'Depression', 'Diabetes', 'Arthritis', 'Sex','Smoking_History']\n","ordinal_ftrs = ['General_Health','Age_Category',]\n","ordinal_cats = [['Poor','Fair','Good','Very Good','Excellent'],\\\n","               ['18-24','25-29','30-34','35-39','40-44','45-49','50-54','55-59','60-64','65-69','70-74','75-79','80+']]\n","num_ftrs = ['Height_(cm)', 'Weight_(kg)', 'BMI', 'Alcohol_Consumption', 'Fruit_Consumption',\n","       'Green_Vegetables_Consumption', 'FriedPotato_Consumption']\n","\n","# one-hot encoder\n","categorical_transformer = Pipeline(steps=[\n","    ('onehot', OneHotEncoder(sparse_output=False,handle_unknown='ignore'))])\n","\n","# ordinal encoder\n","ordinal_transformer = Pipeline(steps=[\n","    ('ordinal', OrdinalEncoder(categories = ordinal_cats))])\n","\n","# standard scaler\n","numeric_transformer = Pipeline(steps=[\n","    ('scaler', StandardScaler())])\n","\n","# collect the transformers\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numeric_transformer, num_ftrs),\n","        ('cat', categorical_transformer, cat_ftrs),\n","        ('ord', ordinal_transformer, ordinal_ftrs)])\n","final_scaler = StandardScaler()\n","prep = Pipeline(steps=[('preprocessor', preprocessor)])"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["#save Subset\n","subset = pd.concat([X_subset, y_subset], axis = 1).to_csv('../data/svm_subset.csv')"]},{"cell_type":"markdown","metadata":{"id":"mo8a2JQjlxmm"},"source":["### baseline recall"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["df = pd.read_csv('../data/svm_subset.csv')\n","X_subset = df.drop(labels=['Heart_Disease'], axis=1)\n","y_subset = df['Heart_Disease']"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":255,"status":"ok","timestamp":1701505076863,"user":{"displayName":"Yicheng Lu","userId":"02397941240840373956"},"user_tz":300},"id":"YwyMF4JSlxmo","outputId":"de9c0d9d-398c-46e1-b844-23159566c38d"},"outputs":[],"source":["N, Y = df['Heart_Disease'].value_counts()\n","baseline_recall = y_subset/(N+Y)"]},{"cell_type":"markdown","metadata":{"id":"VaY_AVO7lxmp"},"source":["### SVM Classifier"]},{"cell_type":"code","execution_count":128,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Random state 1\n","(24709, 18)\n","Fitting 1 folds for each of 6 candidates, totalling 6 fits\n","Random state 2\n","(24709, 18)\n","Fitting 1 folds for each of 6 candidates, totalling 6 fits\n","Random state 3\n","(24709, 18)\n","Fitting 1 folds for each of 6 candidates, totalling 6 fits\n","Random state 4\n","(24709, 18)\n","Fitting 1 folds for each of 6 candidates, totalling 6 fits\n","Random state 5\n","(24709, 18)\n","Fitting 1 folds for each of 6 candidates, totalling 6 fits\n"]}],"source":["nr_states = 5\n","svc_scores = []\n","svc_models = []\n","svc_test_sets = []\n","\n","for i in range(nr_states):\n","    print('Random state', i + 1)\n","\n","    X_train, X_other, y_train, y_other = train_test_split(X_subset, y_subset, train_size=0.6, stratify=y_subset, random_state=56*i)\n","    X_val, X_test, y_val, y_test = train_test_split(X_other, y_other, train_size=0.5, stratify=y_other, random_state=56*i)\n","    column_names = X.columns\n","\n","    X_combined = np.concatenate([X_train, X_val])\n","    X_combined = pd.DataFrame(X_combined, columns=column_names)\n","    y_combined = np.concatenate([y_train, y_val])\n","    split_index = [-1]*len(X_train) + [0]*len(X_val)\n","    fixedval = PredefinedSplit(test_fold=split_index)\n","\n","    print(X_test.shape)\n","\n","    pipe = make_pipeline(prep, SVC(probability=True, random_state=56*i))\n","\n","    param_grid = {\n","        'svc__C': [0.01, 0.1, 1],\n","        'svc__gamma': [0.001, 0.01],\n","        'svc__class_weight': ['balanced']\n","    }\n","\n","    grid = GridSearchCV(pipe, param_grid, cv=fixedval, scoring='recall', verbose=1, n_jobs=-1)\n","    grid.fit(X_combined, y_combined)\n","\n","    best_model = grid.best_estimator_\n","    svc_models.append(best_model)\n","    \n","    for X_save, y_save, dataset_name_save in [(X_train, y_train, 'train'), (X_val, y_val, 'validation'), (X_test, y_test, 'test')]:\n","        y_pred = best_model.predict(X_save)\n","        precision, recall, _ = precision_recall_curve(y_save, best_model.predict_proba(X_save)[:, 1])\n","        auc_pr = auc(recall, precision)\n","        score = {\n","            'dataset': dataset_name_save,\n","            'state': i + 1,\n","            'precision': precision_score(y_save, y_pred, zero_division=0),\n","            'recall': recall_score(y_save, y_pred),\n","            'f2': fbeta_score(y_save, y_pred, beta=2),\n","            'auc-pr': auc_pr\n","        }\n","        svc_scores.append(score)\n","\n","    svc_test_sets.append({'X_test': X_test, 'y_test': y_test, 'state': i + 1})"]},{"cell_type":"code","execution_count":129,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["train recall mean: 0.8589687969297515\n","validation recall mean: 0.8589687969297515\n","test recall mean: 0.8576576576576576\n","test recall standard deviation: 0.005358862388117758\n","144.9575 standard deviations above the baseline\n"]}],"source":["svc_score = pd.DataFrame(svc_scores)\n","svc_score\n","svc_train_recall = svc_score[svc_score['dataset'] == 'train']['recall']\n","svc_val_recall = svc_score[svc_score['dataset'] == 'validation']['recall']\n","svc_test_recall = svc_score[svc_score['dataset'] == 'test']['recall']\n","\n","print('train recall mean:',np.mean(svc_train_recall))\n","print('validation recall mean:',np.mean(svc_train_recall))\n","print('test recall mean:',np.mean(svc_test_recall))\n","print('test recall standard deviation:',np.std(svc_test_recall))\n","print(round((np.mean(svc_test_recall)-baseline_recall)/np.std(svc_test_recall),4),'standard deviations above the baseline')"]},{"cell_type":"code","execution_count":130,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dataset</th>\n","      <th>state</th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f2</th>\n","      <th>auc-pr</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train</td>\n","      <td>1</td>\n","      <td>0.170297</td>\n","      <td>0.855832</td>\n","      <td>0.474117</td>\n","      <td>0.279777</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>validation</td>\n","      <td>1</td>\n","      <td>0.171491</td>\n","      <td>0.863295</td>\n","      <td>0.477801</td>\n","      <td>0.287455</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>test</td>\n","      <td>1</td>\n","      <td>0.171978</td>\n","      <td>0.858859</td>\n","      <td>0.477462</td>\n","      <td>0.281290</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train</td>\n","      <td>2</td>\n","      <td>0.171017</td>\n","      <td>0.859336</td>\n","      <td>0.476094</td>\n","      <td>0.278594</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>validation</td>\n","      <td>2</td>\n","      <td>0.168365</td>\n","      <td>0.852278</td>\n","      <td>0.470244</td>\n","      <td>0.282467</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>test</td>\n","      <td>2</td>\n","      <td>0.170865</td>\n","      <td>0.858859</td>\n","      <td>0.475742</td>\n","      <td>0.284166</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>train</td>\n","      <td>3</td>\n","      <td>0.169733</td>\n","      <td>0.854497</td>\n","      <td>0.472914</td>\n","      <td>0.280559</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>validation</td>\n","      <td>3</td>\n","      <td>0.173685</td>\n","      <td>0.861292</td>\n","      <td>0.480689</td>\n","      <td>0.282697</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>test</td>\n","      <td>3</td>\n","      <td>0.170070</td>\n","      <td>0.862863</td>\n","      <td>0.475481</td>\n","      <td>0.283596</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>train</td>\n","      <td>4</td>\n","      <td>0.170100</td>\n","      <td>0.858335</td>\n","      <td>0.474425</td>\n","      <td>0.286870</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>validation</td>\n","      <td>4</td>\n","      <td>0.169668</td>\n","      <td>0.858788</td>\n","      <td>0.473862</td>\n","      <td>0.266548</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>test</td>\n","      <td>4</td>\n","      <td>0.171848</td>\n","      <td>0.860360</td>\n","      <td>0.477633</td>\n","      <td>0.283668</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>train</td>\n","      <td>5</td>\n","      <td>0.172557</td>\n","      <td>0.866845</td>\n","      <td>0.480325</td>\n","      <td>0.283429</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>validation</td>\n","      <td>5</td>\n","      <td>0.167098</td>\n","      <td>0.841262</td>\n","      <td>0.465580</td>\n","      <td>0.275458</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>test</td>\n","      <td>5</td>\n","      <td>0.167873</td>\n","      <td>0.847347</td>\n","      <td>0.468275</td>\n","      <td>0.280274</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       dataset  state  precision    recall        f2    auc-pr\n","0        train      1   0.170297  0.855832  0.474117  0.279777\n","1   validation      1   0.171491  0.863295  0.477801  0.287455\n","2         test      1   0.171978  0.858859  0.477462  0.281290\n","3        train      2   0.171017  0.859336  0.476094  0.278594\n","4   validation      2   0.168365  0.852278  0.470244  0.282467\n","5         test      2   0.170865  0.858859  0.475742  0.284166\n","6        train      3   0.169733  0.854497  0.472914  0.280559\n","7   validation      3   0.173685  0.861292  0.480689  0.282697\n","8         test      3   0.170070  0.862863  0.475481  0.283596\n","9        train      4   0.170100  0.858335  0.474425  0.286870\n","10  validation      4   0.169668  0.858788  0.473862  0.266548\n","11        test      4   0.171848  0.860360  0.477633  0.283668\n","12       train      5   0.172557  0.866845  0.480325  0.283429\n","13  validation      5   0.167098  0.841262  0.465580  0.275458\n","14        test      5   0.167873  0.847347  0.468275  0.280274"]},"execution_count":130,"metadata":{},"output_type":"execute_result"}],"source":["pd.DataFrame(svc_scores)"]},{"cell_type":"code","execution_count":131,"metadata":{},"outputs":[],"source":["with open('svc_results_24709.pkl', 'wb') as file:\n","    pickle.dump({'scores': svc_scores, 'models': svc_models, 'test_sets': svc_test_sets}, file)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.11.4","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"4bc7e3361d9d4e6acf19e6d3debb289c8e445d5570286ce39fb3214745b4bcdf"}}},"nbformat":4,"nbformat_minor":0}
