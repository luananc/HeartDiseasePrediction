{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"1oIoE7I_uMJ7"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[42m[ OK ]\u001b[0m Python version is 3.11.4\n","\n","\u001b[42m[ OK ]\u001b[0m numpy version 1.24.4 is installed.\n","\u001b[42m[ OK ]\u001b[0m matplotlib version 3.7.2 is installed.\n","\u001b[42m[ OK ]\u001b[0m sklearn version 1.3.0 is installed.\n","\u001b[42m[ OK ]\u001b[0m pandas version 2.0.3 is installed.\n","\u001b[42m[ OK ]\u001b[0m xgboost version 1.7.6 is installed.\n"]},{"name":"stderr","output_type":"stream","text":["Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[42m[ OK ]\u001b[0m shap version 0.42.1 is installed.\n","\u001b[42m[ OK ]\u001b[0m seaborn version 0.12.2 is installed.\n"]}],"source":["from __future__ import print_function\n","from packaging.version import parse as Version\n","from platform import python_version\n","\n","OK = '\\x1b[42m[ OK ]\\x1b[0m'\n","FAIL = \"\\x1b[41m[FAIL]\\x1b[0m\"\n","\n","try:\n","    import importlib\n","except ImportError:\n","    print(FAIL, \"Python version 3.11 is required,\"\n","                \" but %s is installed.\" % sys.version)\n","\n","def import_version(pkg, min_ver, fail_msg=\"\"):\n","    mod = None\n","    try:\n","        mod = importlib.import_module(pkg)\n","        if pkg in {'PIL'}:\n","            ver = mod.VERSION\n","        else:\n","            ver = mod.__version__\n","        if Version(ver) == Version(min_ver):\n","            print(OK, \"%s version %s is installed.\"\n","                  % (lib, min_ver))\n","        else:\n","            print(FAIL, \"%s version %s is required, but %s installed.\"\n","                  % (lib, min_ver, ver))    \n","    except ImportError:\n","        print(FAIL, '%s not installed. %s' % (pkg, fail_msg))\n","    return mod\n","\n","\n","# first check the python version\n","pyversion = Version(python_version())\n","\n","if pyversion >= Version(\"3.11.4\"):\n","    print(OK, \"Python version is %s\" % pyversion)\n","elif pyversion < Version(\"3.11\"):\n","    print(FAIL, \"Python version 3.11 is required,\"\n","                \" but %s is installed.\" % pyversion)\n","else:\n","    print(FAIL, \"Unknown Python version: %s\" % pyversion)\n","\n","    \n","print()\n","requirements = {'numpy': \"1.24.4\", 'matplotlib': \"3.7.2\",'sklearn': \"1.3.0\", \n","                'pandas': \"2.0.3\",'xgboost': \"1.7.6\", 'shap': \"0.42.1\", 'seaborn': \"0.12.2\"}\n","\n","# now the dependencies\n","for lib, required_version in list(requirements.items()):\n","    import_version(lib, required_version)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"L-Sn4UA5t0N0"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline, make_pipeline\n","from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n","from sklearn.model_selection import PredefinedSplit\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import (\n","    precision_score, recall_score, fbeta_score, auc,\n","    precision_recall_curve, average_precision_score\n",")\n","\n","import warnings\n","import pickle"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2465,"status":"ok","timestamp":1701475724001,"user":{"displayName":"Yicheng Lu","userId":"02397941240840373956"},"user_tz":300},"id":"CbjVVDFXt0OJ","outputId":"37b1b179-36c5-47eb-a22c-0f108e5b56dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Full Set\n","X: (308854, 18)\n","y: (308854,)\n"]}],"source":["df = pd.read_csv('../data/CVD_cleaned.csv')\n","df.head()\n","ftrs = df.columns\n","\n","random_state = 56\n","\n","X = df.drop(labels=['Heart_Disease'], axis=1)\n","y = df['Heart_Disease']\n","\n","label_mapping = {'No': 0, 'Yes': 1}\n","y = y.map(label_mapping)\n","\n","X_subset, _, y_subset, _ = train_test_split(X, y, test_size=0.99, stratify=y, random_state=56)\n","\n","print(\"Full Set\")\n","print('X:',X.shape)\n","print('y:',y.shape)\n","#print(\"Subset Set\")\n","#print('X_subset:',X_subset.shape)\n","#print('y_subset:',y_subset.shape)\n","\n","cat_ftrs = ['Checkup','Exercise','Skin_Cancer','Other_Cancer', 'Depression', 'Diabetes', 'Arthritis', 'Sex','Smoking_History']\n","ordinal_ftrs = ['General_Health','Age_Category',]\n","ordinal_cats = [['Poor','Fair','Good','Very Good','Excellent'],\\\n","               ['18-24','25-29','30-34','35-39','40-44','45-49','50-54','55-59','60-64','65-69','70-74','75-79','80+']]\n","num_ftrs = ['Height_(cm)', 'Weight_(kg)', 'BMI', 'Alcohol_Consumption', 'Fruit_Consumption',\n","       'Green_Vegetables_Consumption', 'FriedPotato_Consumption']\n","\n","# one-hot encoder\n","categorical_transformer = Pipeline(steps=[\n","    ('onehot', OneHotEncoder(sparse_output=False,handle_unknown='ignore'))])\n","\n","# ordinal encoder\n","ordinal_transformer = Pipeline(steps=[\n","    ('ordinal', OrdinalEncoder(categories = ordinal_cats))])\n","\n","# standard scaler\n","numeric_transformer = Pipeline(steps=[\n","    ('scaler', StandardScaler())])\n","\n","# collect the transformers\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numeric_transformer, num_ftrs),\n","        ('cat', categorical_transformer, cat_ftrs),\n","        ('ord', ordinal_transformer, ordinal_ftrs)])\n","final_scaler = StandardScaler()\n","prep = Pipeline(steps=[('preprocessor', preprocessor)])"]},{"cell_type":"markdown","metadata":{"id":"h0F_gVQyt0OM"},"source":["### baseline recall"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":137,"status":"ok","timestamp":1701475734522,"user":{"displayName":"Yicheng Lu","userId":"02397941240840373956"},"user_tz":300},"id":"2hF0r7Cet0OM","outputId":"f29d61b6-7bd4-4b9a-ca34-e24912fc34ce"},"outputs":[],"source":["N, Y = df['Heart_Disease'].value_counts()\n","baseline_recall = Y/(N+Y)"]},{"cell_type":"markdown","metadata":{"id":"jEVw8kGJt0ON"},"source":["### Logistic Regression"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Random state 1\n","(61771, 18)\n","Fitting 1 folds for each of 50 candidates, totalling 50 fits\n","Random state 2\n","(61771, 18)\n","Fitting 1 folds for each of 50 candidates, totalling 50 fits\n","Random state 3\n","(61771, 18)\n","Fitting 1 folds for each of 50 candidates, totalling 50 fits\n","Random state 4\n","(61771, 18)\n","Fitting 1 folds for each of 50 candidates, totalling 50 fits\n","Random state 5\n","(61771, 18)\n","Fitting 1 folds for each of 50 candidates, totalling 50 fits\n"]}],"source":["nr_states = 5\n","lg_scores = []\n","lg_models = []\n","lg_test_sets = []\n","\n","for i in range(nr_states):\n","    print('Random state', i + 1)\n","\n","    X_train, X_other, y_train, y_other = train_test_split(X, y, train_size=0.6, stratify=y, random_state=56*i)\n","    X_val, X_test, y_val, y_test = train_test_split(X_other, y_other, train_size=0.5, stratify=y_other, random_state=56*i)\n","    column_names = X.columns\n","\n","    X_combined = np.concatenate([X_train, X_val])\n","    X_combined = pd.DataFrame(X_combined, columns=column_names)\n","    y_combined = np.concatenate([y_train, y_val])\n","    split_index = [-1]*len(X_train) + [0]*len(X_val)\n","    fixedval = PredefinedSplit(test_fold=split_index)\n","\n","    print(X_test.shape)\n","\n","    pipe = make_pipeline(prep, LogisticRegression(solver='saga', max_iter=100000, penalty='elasticnet'))\n","\n","    param_grid = {\n","        'logisticregression__l1_ratio': [0, 0.25, 0.5, 0.75, 1],\n","        'logisticregression__C': [0.01, 0.1, 1, 10, 100],\n","        'logisticregression__class_weight': [None, 'balanced']\n","    }\n","\n","    grid = GridSearchCV(pipe, param_grid, cv=fixedval, scoring='recall', verbose=1, n_jobs=-1)\n","    grid.fit(X_combined, y_combined)\n","\n","    best_model = grid.best_estimator_\n","    lg_models.append(best_model)\n","\n","    for X_save, y_save, dataset_name_save in [(X_train, y_train, 'train'), (X_val, y_val, 'validation'), (X_test, y_test, 'test')]:\n","        y_pred = best_model.predict(X_save)\n","        precision, recall, _ = precision_recall_curve(y_save, best_model.predict_proba(X_save)[:, 1])\n","        auc_pr = auc(recall, precision)\n","        score = {\n","            'dataset': dataset_name_save,\n","            'state': i + 1,\n","            'precision': precision_score(y_save, y_pred),\n","            'recall': recall_score(y_save, y_pred),\n","            'f2': fbeta_score(y_save, y_pred, beta=2),\n","            'auc-pr': auc_pr\n","        }\n","        lg_scores.append(score)\n","\n","    lg_test_sets.append({'X_test': X_test, 'y_test': y_test, 'state': i + 1})\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["#pd.DataFrame(lg_scores)\n","#lg_test_sets[1]['X_test']"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["train recall mean: 0.7906026830407795\n","validation recall mean: 0.7902282739287144\n","test recall mean: 0.7912294753704445\n","test recall standard deviation: 0.008056132421279184\n","88.1787 standard deviations above the baseline\n"]}],"source":["lg_score = pd.DataFrame(lg_scores)\n","lg_score\n","lg_train_recall = lg_score[lg_score['dataset'] == 'train']['recall']\n","lg_val_recall = lg_score[lg_score['dataset'] == 'validation']['recall']\n","lg_test_recall = lg_score[lg_score['dataset'] == 'test']['recall']\n","\n","print('train recall mean:',np.mean(lg_train_recall))\n","print('validation recall mean:',np.mean(lg_val_recall))\n","print('test recall mean:',np.mean(lg_test_recall))\n","print('test recall standard deviation:',np.std(lg_test_recall))\n","print(round((np.mean(lg_test_recall)-baseline_recall)/np.std(lg_test_recall),4),'standard deviations above the baseline')"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["import pickle\n","with open('lg_results_final.pkl', 'wb') as file:\n","    pickle.dump({'scores': lg_scores, 'models': lg_models, 'test_sets': lg_test_sets}, file)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["with open('../results/lg_results_final.pkl', 'rb') as file:\n","    data = pickle.load(file)\n","    lg_scores = data['scores']\n","    lg_models = data['models']\n","    lg_test_sets = data['test_sets']"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.11.4","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"vscode":{"interpreter":{"hash":"4bc7e3361d9d4e6acf19e6d3debb289c8e445d5570286ce39fb3214745b4bcdf"}}},"nbformat":4,"nbformat_minor":0}
